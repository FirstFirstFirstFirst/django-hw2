{% extends 'myapp/base.html' %}

{% block myheader %}
<div class="pricing-header p-3 pb-md-4 mx-auto text-center">
    <h1 class="display-4 fw-normal">Prompt Task Performance Evaluation</h1>
    <p class="fs-5 text-muted">Test how reliably your prompt performs across tasks â€” not prompt writing quality</p>
    <div class="alert alert-info mx-auto" style="max-width: 800px;">
        <strong>What this system does:</strong> Measures how well your prompt works when applied to test cases.<br>
        <strong>What it doesn't do:</strong> Judge whether your prompt text is "well-written" or clearly worded.
    </div>
</div>
{% endblock myheader %}

{% block content %}
<div class="row">
    <!-- Left Column: Prompt Input -->
    <div class="col-md-6">
        <div class="card mb-4">
            <div class="card-header">
                <h5 class="card-title">Submit Prompt for Evaluation</h5>
            </div>
            <div class="card-body">
                <form method="post">
                    {% csrf_token %}
                    <div class="mb-3">
                        <label for="description" class="form-label">Description (Optional)</label>
                        <input type="text" class="form-control" name="description" id="description"
                               placeholder="Brief description of your prompt">
                    </div>
                    <div class="mb-3">
                        <label for="prompt_text" class="form-label">Prompt Text</label>
                        <textarea class="form-control" name="prompt_text" id="prompt_text" rows="8"
                                  placeholder="Example: 'Extract all email addresses from the text and return them as a JSON array'" required></textarea>
                        <div class="form-text">
                            <strong>Best for evaluation:</strong> Prompts that produce structured outputs (JSON, Python code, regex patterns) where correctness can be measured objectively.
                        </div>
                    </div>

                    <!-- Example Prompts Section -->
                    <div class="mb-3">
                        <div class="card border-info">
                            <div class="card-header">
                                <button class="btn btn-link p-0 text-decoration-none" type="button" data-bs-toggle="collapse" data-bs-target="#examplePrompts">
                                    ðŸ’¡ Example Prompts That Work Well
                                </button>
                            </div>
                            <div class="collapse" id="examplePrompts">
                                <div class="card-body small">
                                    <div class="mb-3">
                                        <strong>JSON Output:</strong><br>
                                        <code>"Extract all phone numbers from the text and return them as a JSON array"</code>
                                    </div>
                                    <div class="mb-3">
                                        <strong>Python Code:</strong><br>
                                        <code>"Write a Python function that calculates the area of a circle given the radius"</code>
                                    </div>
                                    <div class="mb-0">
                                        <strong>Regex Pattern:</strong><br>
                                        <code>"Create a regex pattern that matches valid email addresses"</code>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>

                    <!-- Scoring Methodology Section -->
                    <div class="mb-3">
                        <div class="card border-secondary">
                            <div class="card-header">
                                <button class="btn btn-link p-0 text-decoration-none" type="button" data-bs-toggle="collapse" data-bs-target="#scoringInfo">
                                    ðŸ“Š How Scoring Works
                                </button>
                            </div>
                            <div class="collapse" id="scoringInfo">
                                <div class="card-body small">
                                    <h6>Scoring Method:</h6>
                                    <ul class="mb-2">
                                        <li><strong>Syntax Check:</strong> Is the output valid JSON/Python/Regex?</li>
                                        <li><strong>Task Accuracy:</strong> Does it correctly solve the test case?</li>
                                    </ul>
                                    <h6>Score Interpretation:</h6>
                                    <ul class="mb-0">
                                        <li><strong>8-10:</strong> Reliable - consistently generates correct results</li>
                                        <li><strong>5-7:</strong> Inconsistent - works sometimes, fails other times</li>
                                        <li><strong>1-4:</strong> Unreliable - often produces incorrect or invalid results</li>
                                    </ul>
                                </div>
                            </div>
                        </div>
                    </div>
                    <button type="submit" class="btn btn-primary">Evaluate Prompt</button>
                </form>

                {% if error %}
                <div class="alert alert-danger mt-3">{{ error }}</div>
                {% endif %}
            </div>
        </div>

        <!-- Evaluation Result -->
        {% if evaluation_result %}
        <div class="card">
            <div class="card-header bg-success text-white">
                <h5 class="card-title mb-0">Task Performance Results</h5>
            </div>
            <div class="card-body">
                <div class="row">
                    <div class="col-6">
                        <h6>Task Performance Score</h6>
                        <h2 class="text-primary">{{ evaluation_result.average_score }}/10</h2>
                        <small class="text-muted">
                            {% if evaluation_result.average_score >= 8 %}
                                ðŸŸ¢ Reliable performance
                            {% elif evaluation_result.average_score >= 5 %}
                                ðŸŸ¡ Inconsistent performance
                            {% else %}
                                ðŸ”´ Unreliable performance
                            {% endif %}
                        </small>
                    </div>
                    <div class="col-6">
                        <h6>Test Cases Evaluated</h6>
                        <h2 class="text-secondary">{{ evaluation_result.total_test_cases }}</h2>
                        <small class="text-muted">Auto-generated test scenarios</small>
                    </div>
                </div>

                <div class="alert alert-light mt-3">
                    <small>
                        <strong>This score measures:</strong> How reliably your prompt produces correct, valid outputs across different tasks. Higher scores indicate better task performance consistency.
                    </small>
                </div>

                <h6 class="mt-4">Test Case Results:</h6>
                {% for result in evaluation_result.results %}
                <div class="card mb-2">
                    <div class="card-body p-3">
                        <div class="d-flex justify-content-between align-items-center mb-2">
                            <strong>{{ result.test_case.expected_type|upper }}</strong>
                            <span class="badge bg-{% if result.result.score >= 8 %}success{% elif result.result.score >= 6 %}warning{% else %}danger{% endif %}">
                                {{ result.result.score }}/10
                            </span>
                        </div>
                        <p class="mb-2"><strong>Input:</strong> {{ result.test_case.input }}</p>
                        <details>
                            <summary>View Output & Reasoning</summary>
                            <div class="mt-2">
                                <strong>Output:</strong>
                                <pre class="bg-light p-2 mt-1"><code>{{ result.result.output }}</code></pre>
                                <strong>Reasoning:</strong>
                                <p class="mt-1">{{ result.result.reasoning }}</p>
                            </div>
                        </details>
                    </div>
                </div>
                {% endfor %}
            </div>
        </div>
        {% endif %}
    </div>

    <!-- Right Column: Prompt History -->
    <div class="col-md-6">
        <div class="card">
            <div class="card-header d-flex justify-content-between align-items-center">
                <h5 class="card-title mb-0">Prompt History</h5>
                <button class="btn btn-sm btn-outline-primary" onclick="refreshPrompts()">Refresh</button>
            </div>
            <div class="card-body">
                <div id="promptHistory">
                    {% for prompt in recent_prompts %}
                    <div class="card mb-3 prompt-item" data-prompt-id="{{ prompt.id }}">
                        <div class="card-body p-3">
                            <div class="d-flex justify-content-between align-items-start mb-2">
                                <div class="flex-grow-1">
                                    <h6 class="mb-1">{{ prompt.description|default:"Untitled Prompt" }}</h6>
                                    <small class="text-muted">v{{ prompt.version }} â€¢ {{ prompt.created_at|date:"M d, Y H:i" }}</small>
                                </div>
                                <div class="dropdown">
                                    <button class="btn btn-sm btn-outline-secondary dropdown-toggle" type="button"
                                            data-bs-toggle="dropdown">
                                        Actions
                                    </button>
                                    <ul class="dropdown-menu">
                                        <li><a class="dropdown-item" href="#" onclick="viewPrompt({{ prompt.id }})">View Details</a></li>
                                        <li><a class="dropdown-item" href="#" onclick="deletePrompt({{ prompt.id }})">Delete</a></li>
                                    </ul>
                                </div>
                            </div>
                            <p class="mb-2 small">{{ prompt.text|truncatechars:100 }}</p>
                            <div class="row">
                                <div class="col-6">
                                    <small class="text-muted">Test Cases: <span id="tc-count-{{ prompt.id }}">-</span></small>
                                </div>
                                <div class="col-6">
                                    <small class="text-muted">Avg Score: <span id="avg-score-{{ prompt.id }}">-</span></small>
                                </div>
                            </div>
                        </div>
                    </div>
                    {% empty %}
                    <div class="text-center text-muted">
                        <p>No prompts evaluated yet.</p>
                        <p>Submit a prompt to get started!</p>
                    </div>
                    {% endfor %}
                </div>
            </div>
        </div>
    </div>
</div>

<!-- Modal for viewing prompt details -->
<div class="modal fade" id="promptModal" tabindex="-1">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <h5 class="modal-title">Prompt Details</h5>
                <button type="button" class="btn-close" data-bs-dismiss="modal"></button>
            </div>
            <div class="modal-body" id="promptModalBody">
                <!-- Content will be loaded dynamically -->
            </div>
        </div>
    </div>
</div>

<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js"></script>
<script>
let promptModal = new bootstrap.Modal(document.getElementById('promptModal'));

function refreshPrompts() {
    fetch('/prompt-eval/api/prompts/')
        .then(response => response.json())
        .then(data => {
            // Update prompt history
            const historyContainer = document.getElementById('promptHistory');
            if (data.prompts.length === 0) {
                historyContainer.innerHTML = `
                    <div class="text-center text-muted">
                        <p>No prompts evaluated yet.</p>
                        <p>Submit a prompt to get started!</p>
                    </div>
                `;
                return;
            }

            historyContainer.innerHTML = data.prompts.map(prompt => `
                <div class="card mb-3 prompt-item" data-prompt-id="${prompt.id}">
                    <div class="card-body p-3">
                        <div class="d-flex justify-content-between align-items-start mb-2">
                            <div class="flex-grow-1">
                                <h6 class="mb-1">${prompt.description || 'Untitled Prompt'}</h6>
                                <small class="text-muted">v${prompt.version} â€¢ ${new Date(prompt.created_at).toLocaleDateString()}</small>
                            </div>
                            <div class="dropdown">
                                <button class="btn btn-sm btn-outline-secondary dropdown-toggle" type="button"
                                        data-bs-toggle="dropdown">
                                    Actions
                                </button>
                                <ul class="dropdown-menu">
                                    <li><a class="dropdown-item" href="#" onclick="viewPrompt(${prompt.id})">View Details</a></li>
                                    <li><a class="dropdown-item" href="#" onclick="deletePrompt(${prompt.id})">Delete</a></li>
                                </ul>
                            </div>
                        </div>
                        <p class="mb-2 small">${prompt.text.substring(0, 100)}${prompt.text.length > 100 ? '...' : ''}</p>
                        <div class="row">
                            <div class="col-6">
                                <small class="text-muted">Test Cases: ${prompt.test_cases_count}</small>
                            </div>
                            <div class="col-6">
                                <small class="text-muted">Avg Score: ${prompt.avg_score}</small>
                            </div>
                        </div>
                    </div>
                </div>
            `).join('');
        })
        .catch(error => console.error('Error refreshing prompts:', error));
}

function viewPrompt(promptId) {
    // Fetch test cases for this prompt
    fetch(`/prompt-eval/api/prompts/${promptId}/test-cases/`)
        .then(response => response.json())
        .then(data => {
            const modalBody = document.getElementById('promptModalBody');

            if (data.test_cases.length === 0) {
                modalBody.innerHTML = '<p>No test cases found for this prompt.</p>';
                promptModal.show();
                return;
            }

            modalBody.innerHTML = `
                <h6>Test Cases and Results:</h6>
                ${data.test_cases.map(tc => `
                    <div class="card mb-3">
                        <div class="card-body">
                            <div class="d-flex justify-content-between align-items-center mb-2">
                                <strong>${tc.expected_type.toUpperCase()}</strong>
                                ${tc.score ? `<span class="badge bg-${tc.score >= 8 ? 'success' : tc.score >= 6 ? 'warning' : 'danger'}">${tc.score}/10</span>` : '<span class="badge bg-secondary">No Score</span>'}
                            </div>
                            <p class="mb-2"><strong>Input:</strong> ${tc.input}</p>
                            ${tc.output ? `
                                <details>
                                    <summary>View Output & Reasoning</summary>
                                    <div class="mt-2">
                                        <strong>Output:</strong>
                                        <pre class="bg-light p-2 mt-1"><code>${tc.output}</code></pre>
                                        <strong>Reasoning:</strong>
                                        <p class="mt-1">${tc.reasoning}</p>
                                    </div>
                                </details>
                            ` : '<p class="text-muted">No output available</p>'}
                        </div>
                    </div>
                `).join('')}
            `;
            promptModal.show();
        })
        .catch(error => {
            console.error('Error fetching prompt details:', error);
            document.getElementById('promptModalBody').innerHTML = '<p class="text-danger">Error loading prompt details.</p>';
            promptModal.show();
        });
}

function deletePrompt(promptId) {
    if (!confirm('Are you sure you want to delete this prompt and all its test cases?')) {
        return;
    }

    fetch('/prompt-eval/api/prompts/', {
        method: 'DELETE',
        headers: {
            'Content-Type': 'application/json',
            'X-CSRFToken': document.querySelector('[name=csrfmiddlewaretoken]').value
        },
        body: JSON.stringify({ id: promptId })
    })
    .then(response => response.json())
    .then(data => {
        if (data.success) {
            refreshPrompts();
        } else {
            alert('Error deleting prompt: ' + (data.error || 'Unknown error'));
        }
    })
    .catch(error => {
        console.error('Error deleting prompt:', error);
        alert('Error deleting prompt');
    });
}

// Load initial data
document.addEventListener('DOMContentLoaded', function() {
    refreshPrompts();
});
</script>
{% endblock content %}